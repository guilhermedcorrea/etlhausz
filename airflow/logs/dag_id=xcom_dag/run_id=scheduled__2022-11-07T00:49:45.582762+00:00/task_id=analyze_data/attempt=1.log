[2022-11-06T22:20:07.644-0300] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: xcom_dag.analyze_data scheduled__2022-11-07T00:49:45.582762+00:00 [queued]>
[2022-11-06T22:20:07.656-0300] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: xcom_dag.analyze_data scheduled__2022-11-07T00:49:45.582762+00:00 [queued]>
[2022-11-06T22:20:07.656-0300] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-11-06T22:20:07.657-0300] {taskinstance.py:1363} INFO - Starting attempt 1 of 2
[2022-11-06T22:20:07.657-0300] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-11-06T22:20:07.682-0300] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): analyze_data> on 2022-11-07 00:49:45.582762+00:00
[2022-11-06T22:20:07.689-0300] {standard_task_runner.py:55} INFO - Started process 27184 to run task
[2022-11-06T22:20:07.700-0300] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'xcom_dag', 'analyze_data', 'scheduled__2022-11-07T00:49:45.582762+00:00', '--job-id', '525', '--raw', '--subdir', 'DAGS_FOLDER/dag_selenium.py', '--cfg-path', '/tmp/tmpfmnc_8wk']
[2022-11-06T22:20:07.703-0300] {standard_task_runner.py:83} INFO - Job 525: Subtask analyze_data
[2022-11-06T22:20:07.916-0300] {task_command.py:376} INFO - Running <TaskInstance: xcom_dag.analyze_data scheduled__2022-11-07T00:49:45.582762+00:00 [running]> on host debian
[2022-11-06T22:20:08.060-0300] {taskinstance.py:1590} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=xcom_dag
AIRFLOW_CTX_TASK_ID=analyze_data
AIRFLOW_CTX_EXECUTION_DATE=2022-11-07T00:49:45.582762+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-07T00:49:45.582762+00:00
[2022-11-06T22:20:08.073-0300] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1900, in _execute_context
    self.dialect.do_execute(
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.ProgrammingError: can't adapt type 'function'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/debian/etlhausz/airflow/dags/dag_selenium.py", line 54, in analyze_testing_increases
    testing_increases=ti.xcom_pull(key='testing_increase', task_ids=get_testing_increase)
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 2461, in xcom_pull
    results = (
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 2900, in __iter__
    return self._iter().__iter__()
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 2907, in _iter
    result = self.session.execute(
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1714, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1705, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 333, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1572, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1943, in _execute_context
    self._handle_dbapi_exception(
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2124, in _handle_dbapi_exception
    util.raise_(
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 208, in raise_
    raise exception
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1900, in _execute_context
    self.dialect.do_execute(
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.ProgrammingError) can't adapt type 'function'
[SQL: SELECT xcom.task_id AS xcom_task_id, xcom.map_index AS xcom_map_index, xcom.value AS xcom_value 
FROM xcom JOIN dag_run ON xcom.dag_run_id = dag_run.id 
WHERE xcom.key = %(key_1)s AND xcom.task_id = %(task_id_1)s AND xcom.dag_id = %(dag_id_1)s AND xcom.run_id = %(run_id_1)s ORDER BY dag_run.execution_date DESC, xcom.timestamp DESC]
[parameters: {'key_1': 'testing_increase', 'task_id_1': <function get_testing_increase at 0x7fbd6f7e14c0>, 'dag_id_1': 'xcom_dag', 'run_id_1': 'scheduled__2022-11-07T00:49:45.582762+00:00'}]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2022-11-06T22:20:08.095-0300] {taskinstance.py:1401} INFO - Marking task as UP_FOR_RETRY. dag_id=xcom_dag, task_id=analyze_data, execution_date=20221107T004945, start_date=20221107T012007, end_date=20221107T012008
[2022-11-06T22:20:08.104-0300] {standard_task_runner.py:100} ERROR - Failed to execute job 525 for task analyze_data ((psycopg2.ProgrammingError) can't adapt type 'function'
[SQL: SELECT xcom.task_id AS xcom_task_id, xcom.map_index AS xcom_map_index, xcom.value AS xcom_value 
FROM xcom JOIN dag_run ON xcom.dag_run_id = dag_run.id 
WHERE xcom.key = %(key_1)s AND xcom.task_id = %(task_id_1)s AND xcom.dag_id = %(dag_id_1)s AND xcom.run_id = %(run_id_1)s ORDER BY dag_run.execution_date DESC, xcom.timestamp DESC]
[parameters: {'key_1': 'testing_increase', 'task_id_1': <function get_testing_increase at 0x7fbd6f7e14c0>, 'dag_id_1': 'xcom_dag', 'run_id_1': 'scheduled__2022-11-07T00:49:45.582762+00:00'}]
(Background on this error at: https://sqlalche.me/e/14/f405); 27184)
[2022-11-06T22:20:08.131-0300] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-11-06T22:20:08.158-0300] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
