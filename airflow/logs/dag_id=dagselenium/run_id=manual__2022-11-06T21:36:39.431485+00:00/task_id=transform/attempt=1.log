[2022-11-06T18:36:51.715-0300] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: dagselenium.transform manual__2022-11-06T21:36:39.431485+00:00 [queued]>
[2022-11-06T18:36:51.739-0300] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: dagselenium.transform manual__2022-11-06T21:36:39.431485+00:00 [queued]>
[2022-11-06T18:36:51.740-0300] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-11-06T18:36:51.740-0300] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2022-11-06T18:36:51.740-0300] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-11-06T18:36:51.790-0300] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): transform> on 2022-11-06 21:36:39.431485+00:00
[2022-11-06T18:36:51.799-0300] {standard_task_runner.py:55} INFO - Started process 61432 to run task
[2022-11-06T18:36:51.804-0300] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'dagselenium', 'transform', 'manual__2022-11-06T21:36:39.431485+00:00', '--job-id', '449', '--raw', '--subdir', 'DAGS_FOLDER/teste_excom.py', '--cfg-path', '/tmp/tmplhq9g5bm']
[2022-11-06T18:36:51.805-0300] {standard_task_runner.py:83} INFO - Job 449: Subtask transform
[2022-11-06T18:36:52.078-0300] {task_command.py:376} INFO - Running <TaskInstance: dagselenium.transform manual__2022-11-06T21:36:39.431485+00:00 [running]> on host debian
[2022-11-06T18:36:52.398-0300] {taskinstance.py:1590} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dagselenium
AIRFLOW_CTX_TASK_ID=transform
AIRFLOW_CTX_EXECUTION_DATE=2022-11-06T21:36:39.431485+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-11-06T21:36:39.431485+00:00
[2022-11-06T18:36:52.427-0300] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/debian/etlhausz/venv/lib/python3.9/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/debian/etlhausz/airflow/dags/teste_excom.py", line 67, in transform
    order_data = json.loads(extract_data_string)
  File "/usr/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not NoneType
[2022-11-06T18:36:52.443-0300] {taskinstance.py:1401} INFO - Marking task as UP_FOR_RETRY. dag_id=dagselenium, task_id=transform, execution_date=20221106T213639, start_date=20221106T213651, end_date=20221106T213652
[2022-11-06T18:36:52.460-0300] {standard_task_runner.py:100} ERROR - Failed to execute job 449 for task transform (the JSON object must be str, bytes or bytearray, not NoneType; 61432)
[2022-11-06T18:36:52.516-0300] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-11-06T18:36:52.563-0300] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
